{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of Logistic Regression, Decision Trees, XGBoost and Random Forest Regressor for Classification Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Import the necessary libraries as required \n",
    "##### 2. Read excel file to dataframe\n",
    "##### 3. Group categories of 'education' into 'Basic' column\n",
    "##### 4. Create dummy variables\n",
    "##### 5. Split data into train and test data\n",
    "##### 6. Instantiate, fit Logistic Regressor and predict the test data\n",
    "##### 7. Display confusion matrix and classification report for Logistic Regressor\n",
    "##### 8. Instantiate, fit DecisionTrees and predict the test data\n",
    "##### 9. Display confusion matrix and classification report for DecisionTrees\n",
    "##### 10. Instantiate, fit and XGBoost and predict the test data\n",
    "##### 11. Display confusion matrix and classification report for XGBoost\n",
    "##### 12. Instantiate, fit and Random Forest and predict the test data\n",
    "##### 13. Display confusion matrix and classification report for Random Forest \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------Logistic Regression------------------\n",
      "\n",
      "Confusion Matrix:\n",
      " [[10700   269]\n",
      " [  829   559]]\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          no       0.93      0.98      0.95     10969\n",
      "         yes       0.68      0.40      0.50      1388\n",
      "\n",
      "    accuracy                           0.91     12357\n",
      "   macro avg       0.80      0.69      0.73     12357\n",
      "weighted avg       0.90      0.91      0.90     12357\n",
      "\n",
      "\n",
      "------------Decision Trees------------------\n",
      "\n",
      "Confusion Matrix:\n",
      " [[10280   689]\n",
      " [  650   738]]\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          no       0.94      0.94      0.94     10969\n",
      "         yes       0.52      0.53      0.52      1388\n",
      "\n",
      "    accuracy                           0.89     12357\n",
      "   macro avg       0.73      0.73      0.73     12357\n",
      "weighted avg       0.89      0.89      0.89     12357\n",
      "\n",
      "\n",
      "------------XGBoost------------------\n",
      "\n",
      "Confusion Matrix:\n",
      " [[10558   411]\n",
      " [  637   751]]\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          no       0.94      0.96      0.95     10969\n",
      "         yes       0.65      0.54      0.59      1388\n",
      "\n",
      "    accuracy                           0.92     12357\n",
      "   macro avg       0.79      0.75      0.77     12357\n",
      "weighted avg       0.91      0.92      0.91     12357\n",
      "\n",
      "\n",
      "------------Random Forest Regressor------------------\n",
      "\n",
      "Confusion Matrix:\n",
      " [[18396  7183]\n",
      " [11968 13611]]\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.72      0.66     25579\n",
      "         1.0       0.65      0.53      0.59     25579\n",
      "\n",
      "    accuracy                           0.63     51158\n",
      "   macro avg       0.63      0.63      0.62     51158\n",
      "weighted avg       0.63      0.63      0.62     51158\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "# !pip install xgboost\n",
    "\n",
    "bank = pd.read_csv(\"C:/Users/amrut/Documents/UTA documents/Courses/Summer 2020/Data Science/HW/HW3/bank-additional/bank-additional/bank-additional-full.csv\")\n",
    "bank['education']=np.where(bank['education'] =='basic.9y', 'Basic', bank['education'])        #reduce many categories of 'education' column for better modelling\n",
    "bank['education']=np.where(bank['education'] =='basic.6y', 'Basic', bank['education'])        # group categories into 'Basic' column\n",
    "bank['education']=np.where(bank['education'] =='basic.4y', 'Basic', bank['education'])\n",
    "cat_vars=['job','marital','education','default','housing','loan','contact','month','day_of_week','poutcome'] # create dummy variables\n",
    "for var in cat_vars:\n",
    "    cat_list='var'+'_'+var\n",
    "    cat_list = pd.get_dummies(bank[var], prefix=var, drop_first=True)\n",
    "    bank1=bank.join(cat_list)\n",
    "    bank=bank1\n",
    "bank_vars=bank.columns.values.tolist()\n",
    "to_keep=[i for i in bank_vars if i not in cat_vars]\n",
    "bank_final=bank[to_keep]                            # convert list to dataframe\n",
    "X = bank_final.loc[:, bank_final.columns != 'y']    # training set with all columns except 'y'\n",
    "y = bank_final.loc[:, bank_final.columns == 'y']    # test set with only column 'y'\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)   # split data to 70 train and 30 test\n",
    "print(\"------------Logistic Regression------------------\")\n",
    "logreg = LogisticRegression()                       # initialize logistic regressor\n",
    "logreg.fit(X_train, y_train)                        # fit logistic regressor\n",
    "y_pred_1 = logreg.predict(X_test)                   # predict test data in logistic regressor\n",
    "confusion_matrix_1 = confusion_matrix(y_test, y_pred_1) # Instantiate confusion matrix  \n",
    "print(\"\\nConfusion Matrix:\\n {}\".format(confusion_matrix_1))\n",
    "print(\"\\nClassification Report: \\n {}\".format(classification_report(y_test, y_pred_1)))\n",
    "\n",
    "print(\"\\n------------Decision Trees------------------\")\n",
    "tree = DecisionTreeClassifier(random_state=0)       # initialize Decision Trees\n",
    "tree=tree.fit(X_train, y_train)                     # fit logistic regressor\n",
    "y_pred_2=tree.predict(X_test)                       # predict test data using Decision Trees\n",
    "confusion_matrix_2 = confusion_matrix(y_test, y_pred_2)  # Instantiate confusion matrix  \n",
    "print(\"\\nConfusion Matrix:\\n {}\".format(confusion_matrix_2)) \n",
    "print(\"\\nClassification Report: \\n {}\".format(classification_report(y_test, y_pred_2)))\n",
    "\n",
    "print(\"\\n------------XGBoost------------------\")\n",
    "classifier = XGBClassifier()                       # initialize XGBClassifier\n",
    "classifier.fit(X_train, y_train)                   # fit XGBClassifier\n",
    "y_pred_3=classifier.predict(X_test)                # predict test data using XGBClassifier\n",
    "confusion_matrix_3 = confusion_matrix(y_test, y_pred_3) # Instantiate confusion matrix  \n",
    "print(\"\\nConfusion Matrix:\\n {}\".format(confusion_matrix_3))\n",
    "print(\"\\nClassification Report: \\n {}\".format(classification_report(y_test, y_pred_3)))\n",
    "\n",
    "print(\"\\n------------Random Forest Regressor------------------\")\n",
    "smk = SMOTETomek(random_state=42)                             # Perform SMOTE\n",
    "os = RandomOverSampler(random_state=42)\n",
    "X_train_res, y_train_res=os.fit_sample(X_train,y_train)\n",
    "y_train_res[\"y\"] = y_train_res[\"y\"].map({\"no\":0,\"yes\":1})\n",
    "X_train_res.shape,y_train_res.shape\n",
    "\n",
    "sc = StandardScaler()                                        # Perform Standard Scalar\n",
    "X_train = sc.fit_transform(X_train_res)\n",
    "X_test = sc.transform(X_train_res)\n",
    "y_train = sc.fit_transform(y_train_res)\n",
    "y_test = sc.transform(y_train_res)\n",
    "\n",
    "regressor = RandomForestRegressor()                          # initialize RandomForestRegressor                \n",
    "regressor.fit(X_train_res, y_train_res)                      # fit RandomForestRegressor\n",
    "\n",
    "y_pred_4 = regressor.predict(X_test)                         # predict test data using RandomForestRegressor\n",
    "\n",
    "for i in range(0,len(y_pred_4)):                             # Convert predicted data with probability more than 0.1 to 1 and remaining to 0\n",
    "    if y_pred_4[i] > 0.1:\n",
    "        y_pred_4[i]=1\n",
    "    else:\n",
    "        y_pred_4[i]=0\n",
    "\n",
    "for i in range(0,len(y_test)):                               # Convert test data with value -1 to 0 and remaining to 1\n",
    "    if y_test[i] == -1:\n",
    "        y_test[i]=0\n",
    "    else:\n",
    "        y_test[i]=1\n",
    "\n",
    "y_test_list=y_test.tolist()                                  # convert array to list\n",
    "\n",
    "merged_list = []\n",
    "\n",
    "for l in y_test_list:                                        # convert list to array\n",
    "    merged_list += l\n",
    "\n",
    "y_test_array=np.array(merged_list)\n",
    "\n",
    "confusion_matrix_4 = confusion_matrix(y_test, y_pred_4)      # Instantiate confusion matrix  \n",
    "print(\"\\nConfusion Matrix:\\n {}\".format(confusion_matrix_4))\n",
    "print(\"\\nClassification Report: \\n {}\".format(classification_report(y_test, y_pred_4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
